{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import dgl\n",
    "from evaluation.evaluator import Evaluator\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.datasets import TUDataset, QM7b, QM9, ZINC\n",
    "from torch_geometric.utils import to_networkx\n",
    "from pprint import pprint\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset):\n",
    "    with open(f\"data/{dataset}_sampled.pkl\", \"rb\") as f:\n",
    "        adj_list = pickle.load(f)\n",
    "    generated = []\n",
    "    for adj in tqdm(adj_list):\n",
    "        G = nx.from_numpy_matrix(np.array(adj), create_using=nx.DiGraph)\n",
    "        Gcc = sorted(nx.strongly_connected_components(G), key=len, reverse=True)\n",
    "        G0 = G.subgraph(Gcc[0])\n",
    "        generated.append(G0)\n",
    "    if dataset == \"mutag\":\n",
    "        origin_dataset = TUDataset(name = 'MUTAG', root = './data')\n",
    "    elif dataset == \"QM7b\":\n",
    "        origin_dataset = QM7b(root = './data')\n",
    "    elif dataset == \"QM9\":\n",
    "        origin_dataset = QM9(root = './data')\n",
    "    elif dataset == \"ZINC\":\n",
    "        origin_dataset = ZINC(root='./data')\n",
    "    elif dataset in [\"community\", \"ego\", \"er\"]:\n",
    "        with open(f\"data/{dataset}_origin.pkl\", \"rb\") as f:\n",
    "            origin_dataset = pickle.load(f)\n",
    "    if dataset in [\"mutag\", \"QM7b\", \"QM9\", \"ZINC\"]:\n",
    "        original = []\n",
    "        for graph in origin_dataset:\n",
    "            original.append(to_networkx(graph))\n",
    "    elif dataset in [\"community\", \"ego\", \"er\"]:\n",
    "        original = origin_dataset\n",
    "    #min_length = min(1000, min(len(generated), len(original)))\n",
    "    sample=False\n",
    "    if sampled == True:\n",
    "        sample_origin = random.sample(original, k = 10)\n",
    "        sample_generated = random.sample(generated, k = 10)\n",
    "        generated_dgl = [dgl.DGLGraph(g).to(device) for g in sample_origin] # Convert graphs to DGL from NetworkX\n",
    "        original_dgl = [dgl.DGLGraph(g).to(device) for g in sample_generated] # Convert graphs to DGL from NetworkX\n",
    "    else:\n",
    "        generated_dgl = [dgl.DGLGraph(g).to(device) for g in original] # Convert graphs to DGL from NetworkX\n",
    "        original_dgl = [dgl.DGLGraph(g).to(device) for g in generated] # Convert graphs to DGL from NetworkX\n",
    "    return original, generated, original_dgl, generated_dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biggest_components(adj_list):\n",
    "    generated = []\n",
    "    for adj in tqdm(adj_list):\n",
    "        G = nx.from_numpy_matrix(np.array(adj), create_using=nx.DiGraph)\n",
    "        Gcc = sorted(nx.strongly_connected_components(G), key=len, reverse=True)\n",
    "        G0 = G.subgraph(Gcc[0])\n",
    "        generated.append(G0)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_original(dataset):\n",
    "    original = []\n",
    "    if dataset == \"mutag\" or dataset == \"mutag2\":\n",
    "        origin_dataset = TUDataset(name = 'MUTAG', root = './data')\n",
    "    elif dataset == \"QM7b\":\n",
    "        origin_dataset = QM7b(root = './data')\n",
    "    elif dataset == \"QM9\":\n",
    "        origin_dataset = QM9(root = './data')\n",
    "    elif dataset == \"ZINC\":\n",
    "        origin_dataset = ZINC(root='./data')\n",
    "    elif dataset in [\"SynCommunity1000\", \"SynEgo1000\", \"SynER\"]:\n",
    "        with open(f\"data/{dataset}_origin.pkl\", \"rb\") as f:\n",
    "            origin_dataset = pickle.load(f)\n",
    "    if dataset in [\"mutag\", \"QM7b\", \"QM9\", \"ZINC\", \"mutag2\"]:\n",
    "        original = []\n",
    "        for graph in origin_dataset:\n",
    "            original.append(to_networkx(graph))\n",
    "    elif dataset in [\"SynCommunity1000\", \"SynEgo1000\", \"SynER\"]:\n",
    "        original = origin_dataset\n",
    "    if len(original) > 1000:\n",
    "        original = original[:1000]\n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result(dataset):\n",
    "    original_dataset = read_original(dataset)\n",
    "    with open(f\"data/{dataset}/{dataset}_ddim_500_sampled.pkl\", \"rb\") as f:\n",
    "        ddim_500 = pickle.load(f)\n",
    "        ddim_500 = get_biggest_components(ddim_500)\n",
    "    with open(f\"data/{dataset}/{dataset}_ddim_800_sampled.pkl\", \"rb\") as f:\n",
    "        ddim_800 = pickle.load(f)\n",
    "        ddim_800 = get_biggest_components(ddim_800)\n",
    "    with open(f\"data/{dataset}/{dataset}_ddpm_1000_sampled.pkl\", \"rb\") as f:\n",
    "        ddpm_1000 = pickle.load(f)\n",
    "        ddpm_1000 = get_biggest_components(ddpm_1000)\n",
    "    print(len(original_dataset), len(ddim_500), len(ddim_800), len(ddpm_1000))\n",
    "    ddim_500_dgl = [dgl.DGLGraph(g).to(device) for g in ddim_500] \n",
    "    ddim_800_dgl = [dgl.DGLGraph(g).to(device) for g in ddim_800] \n",
    "    ddpm_1000_dgl = [dgl.DGLGraph(g).to(device) for g in ddpm_1000]\n",
    "    original_dgl = [dgl.DGLGraph(g).to(device) for g in original_dataset]\n",
    "\n",
    "    return [ddim_500_dgl, ddim_800_dgl, ddpm_1000_dgl, original_dgl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 14578.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 14363.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 14787.66it/s]\n",
      "c:\\users\\deukryeol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\dgl\\heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 8515.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 8553.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 8475.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 3144.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 3117.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 3124.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
      "Extracting data\\raw\\qm9_v3.zip\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 6374.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 5940.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 6777.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm7b.mat\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2115.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2124.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2129.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2782.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2802.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2814.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"SynCommunity1000\", \"SynEgo1000\", \"SynER\",\"QM9\", \"QM7b\", \"ZINC\"]\n",
    "result = []\n",
    "for dataset in datasets:\n",
    "    result.append(read_result(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "[[0.833226   0.59283437 1.80600592 0.75215024 1.99642881 0.86292463]\n",
      " [0.93704051 0.79310009 1.66027908 0.6218106  1.99140175 0.31654298]\n",
      " [0.85328148 0.69396552 0.99384151 0.54546785 1.55730841 0.6080448 ]\n",
      " [1.29659188 1.01460373 1.80816129 0.51197149 1.99626183 0.66484903]\n",
      " [0.94756439 0.94513273 1.76171574 1.48920935 0.71554448 1.30654009]\n",
      " [1.53965168 1.37627009 1.81169147 0.89296407 1.99454928 0.43463546]]\n",
      "\n",
      "[[      75       47   691641      643 33046116  1246535]\n",
      " [     125       97     2481       32   163187     4371]\n",
      " [      87       77       52       68      931       84]\n",
      " [     369      231   330819      241 16249224   598135]\n",
      " [     148      206     2007      691       38     4151]\n",
      " [     690      545    23362      125  1678275    46153]]\n"
     ]
    }
   ],
   "source": [
    "heatmap_mmd = np.array([[0] * len(result)] * len(result), dtype=float)\n",
    "heatmap_fid = np.array([[0] * len(result)] * len(result), dtype=int)\n",
    "\n",
    "for i, result1 in enumerate(result):\n",
    "    for j, result2 in enumerate(result):\n",
    "        eval_result = evaluator.evaluate_all(generated_dataset = result2[0], reference_dataset = result1[3])\n",
    "        mmd = eval_result['mmd_rbf']\n",
    "        fid = eval_result['fid']\n",
    "        heatmap_mmd[i,j] = mmd\n",
    "        heatmap_fid[i,j] = fid\n",
    "print(heatmap_mmd)\n",
    "print(\"\")\n",
    "print(heatmap_fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SynCommunity1000', 'SynEgo1000', 'SynER', 'mutag', 'QM9', 'QM7b']\n",
      "[[      41       28    70801     1890      428  5325510]\n",
      " [      88       69     3774       31        8   594171]\n",
      " [      52       39        2       21       29     1126]\n",
      " [     353      270   125564     1497      325 10831175]\n",
      " [     339      219    65964     1370      156  5018118]\n",
      " [     119      118       83      106      112        3]]\n"
     ]
    }
   ],
   "source": [
    "print(datasets)\n",
    "print(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJnUlEQVR4nO3dT4hd9RnG8edxGomoxUWthExoXIggLowM2VgKTbHEP6hLBV0Js6klpQvRpYtuxU03g0pbtAZBBbG2NtRYEfw3idGaRCWIxQRhCCI1DWqNTxdzg2OYyT1z55w5J6/fDwzeO/d6fZF853fPmdzfcRIBqOO8vgcA0C6iBoohaqAYogaKIWqgmB908aK2w08LVLPtkr4n+NZHJ6XjX8bLPdZJ1OdJ2tjFCxcy1fcAZzjV9wDngPlf9D3Bt2b+sfJjLKhAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMY2itr3T9vu2j9i+r+uhAExubNS2pyT9XtINkq6SdIftq7oeDMBkmqzU2yUdSfJhkq8k7ZZ0a7djAZhUk6g3S/p4yf2jo+99h+1Z2/O259lJHOhPazufJJmTNCdJUzZdAz1pslIfk7Rlyf3p0fcADFCTqN+UdIXty22fL+l2Sc92OxaASY19+53ka9v3SHpBi/vlPZrkYOeTAZhIo2PqJM9Ler7jWQC0gL9RBhRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFO2t/PYMrOxtZfFejXFX0PsMQHkk4mXu4xVmqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoJixUdt+1PaC7XfXYyAAa9Nkpf6DpJ0dzwGgJWOjTvKypE/XYRYALWh0feombM9KmpWkZfdYAbAuWos6yZykOWlxj7K2XhfA6nD2GyiGqIFimvxK6wlJr0q60vZR23d3PxaASY09pk5yx3oMAqAdvP0GiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGCft72cwZWdj668K4LQvJJ1Klt1kiJUaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKaXCBvi+29tg/ZPmh713oMBmAyYz9PbXuTpE1J9tu+WNI+SbclObTSv8PnqYFurenz1Ek+SbJ/dPtzSYclbW51QgCtGXsp26Vsb5W0TdLryzw2K2lWkpb98QFgXTTezsj2RZL+Kel3SZ4+23N5+w10a83bGdneIOkpSY+PCxpAv5qc/bakRyQdTvJg9yMBWIsmK/V1ku6StMP2gdHXjR3PBWBCbBEMnIPYIhj4HiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgmFXtfIL2bOh7gDP8r+8BzgH/7eDDT5OamZlZ8TFWaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKaXLVy42237D9tu2Dth9Yj8EATKbJ56m/lLQjyYnRdapfsf3XJK91PBuACYyNOouXxTwxurth9DWcT4sD+I5Gx9S2p2wfkLQgaU+S15d5zqztedvzFA/0p1HUSU4luUbStKTttq9e5jlzSWaSzCx70VwA62JVZ7+TfCZpr6SdnUwDYM2anP2+1PYlo9sXSLpe0nsdzwVgQk3Ofm+S9EfbU1r8IfBkkue6HQvApJqc/X5H0rZ1mAVAC/gbZUAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRTT5FNa6MA3fQ+A1dsxoO0/Plj5IVZqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoppHPXowvNv2ebieMCArWal3iXpcFeDAGhHo6htT0u6SdLD3Y4DYK2artQPSbpXZ9mww/as7Xnb82ljMgATGRu17ZslLSTZd7bnJZlLMpNkZkCbvgDfO01W6usk3WL7I0m7Je2w/VinUwGY2Niok9yfZDrJVkm3S3oxyZ2dTwZgIvyeGihmVVsEJ3lJ0kudTAKgFazUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFO2t98aMrOxtZfFcBpX0g6lSy7yRArNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFNLpA3uja1J9LOiXp6yQzXQ4FYHKruerlz5Mc72wSAK3g7TdQTNOoI+nvtvfZnl3uCbZnbc/bnm9/LxUATTXazsj25iTHbP9Y0h5Jv07y8krPZzsjoFtr3s4oybHRPxckPSNpe2vTAWjV2KhtX2j74tO3Jf1S0rtdDwZgMk3Ofl8m6Rnbp5//5yR/63QqABNji2DgHMQWwcD3CFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFrGaPssa+kY6flP7dwkv9SNKQ9kVjnrMb2jzS8GZqa56frPRAJ5/Saovt+SHtXMo8Zze0eaThzbQe8/D2GyiGqIFihh71XN8DnIF5zm5o80jDm6nzeQZ9TA1g9Ya+UgNYJaIGihlk1LZ32n7f9hHb9w1gnkdtL9gexNbItrfY3mv7kO2Dtnf1PM9G22/Yfns0zwN9znOa7Snbb9l+ru9ZpMULTdr+l+0Dtuc7++8M7Zja9pSkDyRdL+mopDcl3ZHkUI8z/UzSCUl/SnJ1X3MsmWeTpE1J9o/2ZN8n6ba+/h95cf/oC5OcsL1B0iuSdiV5rY95lsz1W0kzkn6Y5OY+ZxnN85Gkma4vNDnElXq7pCNJPkzylaTdkm7tc6DRJYY+7XOGpZJ8kmT/6Pbnkg5L2tzjPElyYnR3w+ir19XC9rSkmyQ93OccfRhi1Jslfbzk/lH1+Ad26GxvlbRN0us9zzFl+4CkBUl7kvQ6j6SHJN0r6Zue51hq7IUm2zDEqNGQ7YskPSXpN0n+0+csSU4luUbStKTttns7TLF9s6SFJPv6mmEFP01yraQbJP1qdFjXuiFGfUzSliX3p0ffwxKjY9enJD2e5Om+5zktyWeS9kra2eMY10m6ZXQMu1vSDtuP9TiPpPW70OQQo35T0hW2L7d9vqTbJT3b80yDMjox9Yikw0keHMA8l9q+ZHT7Ai2e5Hyvr3mS3J9kOslWLf75eTHJnX3NI63vhSYHF3WSryXdI+kFLZ4AejLJwT5nsv2EpFclXWn7qO27+5xHiyvRXVpcgQ6Mvm7scZ5NkvbafkeLP5T3JBnEr5EG5DJJr9h+W9Ibkv7S1YUmB/crLQBrM7iVGsDaEDVQDFEDxRA1UAxRA8UQNVAMUQPF/B9fiVNuqaJw7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orthogonal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\n",
      "Extracting data\\molecules.zip\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\n",
      "Processing...\n",
      "Processing train dataset: 100%|█████████████████████████████████████████████| 220011/220011 [00:11<00:00, 19310.30it/s]\n",
      "Processing val dataset: 100%|█████████████████████████████████████████████████| 24445/24445 [00:02<00:00, 11220.37it/s]\n",
      "Processing test dataset: 100%|██████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 16350.41it/s]\n",
      "Done!\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2860.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2758.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 2916.64it/s]\n",
      "c:\\users\\deukryeol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\dgl\\heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 960 960 960\n",
      "*********************************\n",
      "Dataset : ZINC\n",
      "DDIM 500 Result\n",
      "{'activations_time': 0.45908665657043457,\n",
      " 'coverage': 0.0,\n",
      " 'coverage_time': 0.7019360065460205,\n",
      " 'density': 0.0,\n",
      " 'density_time': 0.7019360065460205,\n",
      " 'f1_dc': 1e-05,\n",
      " 'f1_dc_time': 0.7019360065460205,\n",
      " 'f1_pr': 1e-05,\n",
      " 'f1_pr_time': 0.8677167892456055,\n",
      " 'fid': 46153.50098832186,\n",
      " 'fid_time': 0.46803927421569824,\n",
      " 'mmd_linear': 6708.1904,\n",
      " 'mmd_linear_time': 0.45908665657043457,\n",
      " 'mmd_rbf': 0.4346354603767395,\n",
      " 'mmd_rbf_time': 0.9890601634979248,\n",
      " 'precision': 0.0,\n",
      " 'precision_time': 0.8677167892456055,\n",
      " 'recall': 0.0,\n",
      " 'recall_time': 0.8677167892456055}\n",
      "\n",
      "DDIM 800 Result\n",
      "{'activations_time': 0.2852919101715088,\n",
      " 'coverage': 0.0,\n",
      " 'coverage_time': 0.5161573886871338,\n",
      " 'density': 0.0,\n",
      " 'density_time': 0.5161573886871338,\n",
      " 'f1_dc': 1e-05,\n",
      " 'f1_dc_time': 0.5161573886871338,\n",
      " 'f1_pr': 1e-05,\n",
      " 'f1_pr_time': 0.6617240905761719,\n",
      " 'fid': 48887.86656726349,\n",
      " 'fid_time': 0.2942688465118408,\n",
      " 'mmd_linear': 6639.0767,\n",
      " 'mmd_linear_time': 0.2852919101715088,\n",
      " 'mmd_rbf': 0.430660605430603,\n",
      " 'mmd_rbf_time': 0.8482832908630371,\n",
      " 'precision': 0.0,\n",
      " 'precision_time': 0.6617240905761719,\n",
      " 'recall': 0.0,\n",
      " 'recall_time': 0.6617240905761719}\n",
      "\n",
      "DDPM 1000 Result\n",
      "{'activations_time': 0.27733898162841797,\n",
      " 'coverage': 0.0,\n",
      " 'coverage_time': 0.5120975971221924,\n",
      " 'density': 0.0,\n",
      " 'density_time': 0.5120975971221924,\n",
      " 'f1_dc': 1e-05,\n",
      " 'f1_dc_time': 0.5120975971221924,\n",
      " 'f1_pr': 1e-05,\n",
      " 'f1_pr_time': 0.6644060611724854,\n",
      " 'fid': 48889.83877770635,\n",
      " 'fid_time': 0.28632426261901855,\n",
      " 'mmd_linear': 6639.9697,\n",
      " 'mmd_linear_time': 0.27733898162841797,\n",
      " 'mmd_rbf': 0.4306526184082031,\n",
      " 'mmd_rbf_time': 0.8200671672821045,\n",
      " 'precision': 0.0,\n",
      " 'precision_time': 0.6644060611724854,\n",
      " 'recall': 0.0,\n",
      " 'recall_time': 0.6644060611724854}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(device=device)\n",
    "def eval_(dataset):\n",
    "    i500, i800, p1000, g = read_result(dataset)\n",
    "    eval1 = evaluator.evaluate_all(generated_dataset=i500, reference_dataset=g) \n",
    "    eval2 = evaluator.evaluate_all(generated_dataset=i800, reference_dataset=g) \n",
    "    eval3 = evaluator.evaluate_all(generated_dataset=p1000, reference_dataset=g) \n",
    "    \n",
    "    print(\"*********************************\")\n",
    "    print(f\"Dataset : {dataset}\")\n",
    "    print(\"DDIM 500 Result\")\n",
    "    pprint(eval1)\n",
    "    print(\"\")\n",
    "    print(\"DDIM 800 Result\")\n",
    "    pprint(eval2)\n",
    "    print(\"\")\n",
    "    print(\"DDPM 1000 Result\")\n",
    "    pprint(eval3)\n",
    "    print(\"\")\n",
    "datasets = [\"ZINC\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    eval_(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"community\", \"ego\", \"er\", \"mutag\", \"mutag2\", \"QM9\", \"QM7b\"]\n",
    "\n",
    "for dataset in datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origin, generated, origin_dgl, generated_dgl = read_dataset(\"mutag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = 10\n",
    "#pos = nx.spring_layout(origin[k])\n",
    "#nx.draw_networkx(origin[k], pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = nx.spring_layout(generated[k])\n",
    "#nx.draw_networkx(generated[k], pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 16303.60it/s]\n",
      "c:\\users\\deukryeol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\dgl\\heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community\n",
      "orthogonal\n",
      "{'activations_time': 0.45547032356262207,\n",
      " 'coverage': 0.005208333333333333,\n",
      " 'coverage_time': 0.6989173889160156,\n",
      " 'density': 0.0024000000000000002,\n",
      " 'density_time': 0.6989173889160156,\n",
      " 'f1_dc': 0.0032972296263928343,\n",
      " 'f1_dc_time': 0.6989173889160156,\n",
      " 'f1_pr': 0.006987008824895495,\n",
      " 'f1_pr_time': 0.8153517246246338,\n",
      " 'fid': 24315.786768837632,\n",
      " 'fid_time': 0.46442198753356934,\n",
      " 'mmd_linear': 15382.181,\n",
      " 'mmd_linear_time': 0.45547032356262207,\n",
      " 'mmd_rbf': 1.0491768568754196,\n",
      " 'mmd_rbf_time': 1.0433690547943115,\n",
      " 'precision': 0.006,\n",
      " 'precision_time': 0.8153517246246338,\n",
      " 'recall': 0.008333333333333333,\n",
      " 'recall_time': 0.8153517246246338}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 8021.46it/s]\n",
      "c:\\users\\deukryeol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\dgl\\heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego\n",
      "orthogonal\n",
      "fid calculation produces singular product; adding 1e-06 to diagonal of cov estimates\n",
      "{'activations_time': 0.306180477142334,\n",
      " 'coverage': 0.013541666666666667,\n",
      " 'coverage_time': 0.5615682601928711,\n",
      " 'density': 0.15243902439024393,\n",
      " 'density_time': 0.5615682601928711,\n",
      " 'f1_dc': 0.02489072002100099,\n",
      " 'f1_dc_time': 0.5615682601928711,\n",
      " 'f1_pr': 0.15407454717486369,\n",
      " 'f1_pr_time': 0.6589131355285645,\n",
      " 'fid': 5771.434543238462,\n",
      " 'fid_time': 0.3189389705657959,\n",
      " 'mmd_linear': 1815.9868,\n",
      " 'mmd_linear_time': 0.306180477142334,\n",
      " 'mmd_rbf': 0.787305636331439,\n",
      " 'mmd_rbf_time': 0.7449591159820557,\n",
      " 'precision': 0.3353658536585366,\n",
      " 'precision_time': 0.6589131355285645,\n",
      " 'recall': 0.1,\n",
      " 'recall_time': 0.6589131355285645}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [00:00<00:00, 3166.33it/s]\n",
      "c:\\users\\deukryeol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\dgl\\heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er\n",
      "orthogonal\n",
      "{'activations_time': 0.23337626457214355,\n",
      " 'coverage': 0.011458333333333333,\n",
      " 'coverage_time': 0.4594249725341797,\n",
      " 'density': 0.09473684210526316,\n",
      " 'density_time': 0.4594249725341797,\n",
      " 'f1_dc': 0.020460134120326743,\n",
      " 'f1_dc_time': 0.4594249725341797,\n",
      " 'f1_pr': 0.2318826344066076,\n",
      " 'f1_pr_time': 0.5854203701019287,\n",
      " 'fid': 1541.19797410613,\n",
      " 'fid_time': 0.24135494232177734,\n",
      " 'mmd_linear': 277.04047,\n",
      " 'mmd_linear_time': 0.23337626457214355,\n",
      " 'mmd_rbf': 0.8561420366168022,\n",
      " 'mmd_rbf_time': 0.6392085552215576,\n",
      " 'precision': 0.13157894736842105,\n",
      " 'precision_time': 0.5854203701019287,\n",
      " 'recall': 0.975,\n",
      " 'recall_time': 0.5854203701019287}\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"community\", \"ego\", \"er\"]\n",
    "import random\n",
    "for dataset in datasets:\n",
    "    origin, generated, origin_dgl, generated_dgl = read_dataset(dataset)\n",
    "    print(dataset)\n",
    "    eval_(origin_dgl, generated_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
